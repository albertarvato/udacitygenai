{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35354cd",
   "metadata": {},
   "source": [
    "# Project 1 - Apply Lightweight Fine-Tuning to a Foundation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec7549e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.13.2\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fb3ff",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de8d76bb",
   "metadata": {},
   "source": [
    "## Loading and Evaluating a Foundation Model\n",
    "\n",
    "TODO: In the cells below, load your chosen pre-trained Hugging Face model and evaluate its performance prior to fine-tuning. This step includes loading an appropriate tokenizer and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad741096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.8.0+cpu\n"
     ]
    }
   ],
   "source": [
    "# Optional: !pip install -r requirements.txt\n",
    "import os\n",
    "import random\n",
    "import datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from transformers.utils import logging\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    AutoPeftModelForCausalLM,\n",
    "    AutoPeftModelForSequenceClassification,\n",
    ")\n",
    "\n",
    "# ---- Simple debugging helpers ----\n",
    "VERBOSE = True  # set to False to silence debug prints\n",
    "\n",
    "def debug_print(*args, **kwargs):\n",
    "    if VERBOSE:\n",
    "        print(*args, **kwargs)\n",
    "\n",
    "# ---- Reproducibility ----\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# ---- Logging ----\n",
    "logging.set_verbosity_warning()\n",
    "debug_print(\"PyTorch version:\", torch.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f551c63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splits: ['train', 'validation', 'test']\n",
      "Train size: 16000 Validation size: 2000 Test size: 2000\n",
      "Train/valid sizes: 14400 1600\n",
      "Train sample: {'text': 'when an alcoholic stood dribbling over a food counter', 'label': 3}\n",
      "Validation sample: {'text': 'while cycling in the country', 'label': 4}\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "# dair-ai/emotion contains 6 labels: sadness, joy, love, anger, fear, surprise\n",
    "dataset = load_dataset(\"dair-ai/emotion\")\n",
    "debug_print(\"Dataset splits:\", list(dataset.keys()))\n",
    "debug_print(\"Train size:\", len(dataset[\"train\"]), \"Validation size:\", len(dataset.get(\"validation\", [])), \"Test size:\", len(dataset[\"test\"]))\n",
    "\n",
    "# Split the train set into train/validation (stratified by default)\n",
    "train_valid = dataset[\"train\"].train_test_split(test_size=0.1, seed=SEED)\n",
    "debug_print(\"Train/valid sizes:\", len(train_valid[\"train\"]), len(train_valid[\"test\"]))\n",
    "\n",
    "# Inspect a couple of samples\n",
    "debug_print(\"Train sample:\", train_valid[\"train\"][0])\n",
    "debug_print(\"Validation sample:\", train_valid[\"test\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4935cb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tokenizer: distilbert-base-uncased\n",
      "Tokenizing train and validation splits...\n",
      "Tokenized features: ['text', 'label', 'input_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "# Initialize the tokenizer\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "debug_print(\"Loaded tokenizer:\", model_name)\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)\n",
    "\n",
    "# Tokenize datasets\n",
    "debug_print(\"Tokenizing train and validation splits...\")\n",
    "tokenized_train = train_valid[\"train\"].map(tokenize, batched=True)\n",
    "tokenized_test = train_valid[\"test\"].map(tokenize, batched=True)\n",
    "debug_print(\"Tokenized features:\", tokenized_train.column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f28c4a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num labels: 6 Labels: ['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']\n",
      "Train sample: {'text': 'when an alcoholic stood dribbling over a food counter', 'label': 3}\n",
      "Validation sample: {'text': 'while cycling in the country', 'label': 4}\n",
      "Model classifier out_features: 6\n"
     ]
    }
   ],
   "source": [
    "# Build label mapping from dataset (prevents label-out-of-range issues)\n",
    "label_list = dataset[\"train\"].features[\"label\"].names\n",
    "num_labels = len(label_list)\n",
    "id2label = {i: name for i, name in enumerate(label_list)}\n",
    "label2id = {name: i for i, name in enumerate(label_list)}\n",
    "debug_print(\"Num labels:\", num_labels, \"Labels:\", label_list)\n",
    "\n",
    "# Show a couple of items to verify labels are within [0, num_labels)\n",
    "debug_print(\"Train sample:\", train_valid[\"train\"][0])\n",
    "debug_print(\"Validation sample:\", train_valid[\"test\"][0])\n",
    "\n",
    "# Initialize the model with correct label space\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_labels,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "debug_print(\"Model classifier out_features:\", model.classifier.out_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "019b9f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model head: Linear(in_features=768, out_features=6, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# Quick model check (print only the head to keep output short)\n",
    "debug_print(\"Model head:\", model.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5176b07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: 66,958,086 total | 595,206 trainable\n"
     ]
    }
   ],
   "source": [
    "# Freeze the base model parameters (train only the classifier head)\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "debug_print(f\"Parameters: {total_params:,} total | {total_trainable_params:,} trainable\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8b60aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collator set. Example batch keys: dict_keys(['text', 'label', 'input_ids', 'attention_mask'])\n",
      "Training args ready. Epochs: 5\n",
      "Trainer initialized for base model.\n"
     ]
    }
   ],
   "source": [
    "# Prepare for training\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": (predictions == labels).mean()}\n",
    "\n",
    "# Re-tokenize to be safe if previous cells were re-run\n",
    "tokenized_train = train_valid[\"train\"].map(tokenize, batched=True)\n",
    "tokenized_test = train_valid[\"test\"].map(tokenize, batched=True)\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer, padding=True)\n",
    "debug_print(\"Collator set. Example batch keys:\", tokenized_train.features.keys())\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"./results/{model_name}/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"),\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_steps=300,\n",
    "    learning_rate=3e-5,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "debug_print(\"Training args ready. Epochs:\", training_args.num_train_epochs)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "debug_print(\"Trainer initialized for base model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83604aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating base model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 42:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base eval: {'eval_loss': 1.795680284500122, 'eval_model_preparation_time': 0.0011, 'eval_accuracy': 0.134375, 'eval_runtime': 12.494, 'eval_samples_per_second': 128.062, 'eval_steps_per_second': 4.002}\n",
      "{'base_eval_accuracy': 0.134375}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the base model\n",
    "debug_print(\"Evaluating base model...\")\n",
    "base_eval = trainer.evaluate()\n",
    "debug_print(\"Base eval:\", base_eval)\n",
    "base_accuracy = base_eval.get(\"eval_accuracy\")\n",
    "print({\"base_eval_accuracy\": base_accuracy})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52a229",
   "metadata": {},
   "source": [
    "## Performing Parameter-Efficient Fine-Tuning\n",
    "\n",
    "TODO: In the cells below, create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5775fadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer reloaded for LoRA: distilbert-base-uncased\n",
      "Configuring LoRA...\n",
      "LoRA adapters injected.\n",
      "trainable params: 1,037,574 || all params: 67,995,660 || trainable%: 1.5259\n"
     ]
    }
   ],
   "source": [
    "# Set up a fresh model for LoRA training (same label mapping)\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "debug_print(\"Tokenizer reloaded for LoRA:\", model_name)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_labels,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True,\n",
    ")\n",
    "\n",
    "debug_print(\"Configuring LoRA...\")\n",
    "config = LoraConfig(\n",
    "    task_type=\"SEQ_CLS\",\n",
    "    target_modules=[\"q_lin\", \"k_lin\", \"v_lin\"],\n",
    "    r=16,\n",
    "    lora_alpha=64,\n",
    "    lora_dropout=0.05,\n",
    ")\n",
    "\n",
    "fine_tuned_model = get_peft_model(model, config)\n",
    "debug_print(\"LoRA adapters injected.\")\n",
    "\n",
    "# Print trainable parameters\n",
    "fine_tuned_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "894046c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\conta\\AppData\\Local\\Temp\\ipykernel_18880\\3711282236.py:21: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  lora_trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# Prepare for training\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": (predictions == labels).mean()}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"./results/{model_name}-lora/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"),\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_steps=300,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "lora_trainer = Trainer(\n",
    "    model=fine_tuned_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c4d4c908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting LoRA training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2250' max='2250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2250/2250 41:11, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.994676</td>\n",
       "      <td>0.658750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.419200</td>\n",
       "      <td>0.661467</td>\n",
       "      <td>0.753750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.781300</td>\n",
       "      <td>0.546919</td>\n",
       "      <td>0.798125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.598100</td>\n",
       "      <td>0.504998</td>\n",
       "      <td>0.811250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.492082</td>\n",
       "      <td>0.817500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\conta\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\conta\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\conta\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\conta\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished. Last metrics: {'train_runtime': 2472.4807, 'train_samples_per_second': 29.121, 'train_steps_per_second': 0.91, 'total_flos': 997149382636032.0, 'train_loss': 0.8003791842990451, 'epoch': 5.0}\n"
     ]
    }
   ],
   "source": [
    "# Train the LoRA model\n",
    "debug_print(\"Starting LoRA training...\")\n",
    "train_out = lora_trainer.train()\n",
    "debug_print(\"Training finished. Last metrics:\", getattr(train_out, \"metrics\", {}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b47abf88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LoRA model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\conta\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:13]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA eval: {'eval_loss': 0.49208173155784607, 'eval_accuracy': 0.8175, 'eval_runtime': 13.4517, 'eval_samples_per_second': 118.944, 'eval_steps_per_second': 3.717, 'epoch': 5.0}\n",
      "{'lora_eval_accuracy': 0.8175}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the LoRA model\n",
    "debug_print(\"Evaluating LoRA model...\")\n",
    "lora_eval = lora_trainer.evaluate()\n",
    "debug_print(\"LoRA eval:\", lora_eval)\n",
    "print({\"lora_eval_accuracy\": lora_eval.get(\"eval_accuracy\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3bb6b396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the loRA model\n",
    "fine_tuned_model.save_pretrained(f\"./peft/{model_name}-lora\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b12c6",
   "metadata": {},
   "source": [
    "## Performing Inference with a PEFT Model\n",
    "\n",
    "TODO: In the cells below, load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bc96905a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval device: cpu | use_mps: False | load_dtype: None\n",
      "PEFT model loaded and moved to device.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\conta\\AppData\\Local\\Temp\\ipykernel_18880\\2366408042.py:20: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  lora_eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 00:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PEFT eval results: {'eval_loss': 0.49208173155784607, 'eval_model_preparation_time': 0.0022, 'eval_accuracy': 0.8175, 'eval_runtime': 12.8343, 'eval_samples_per_second': 124.666, 'eval_steps_per_second': 15.583}\n"
     ]
    }
   ],
   "source": [
    "# Load the saved PEFT model and evaluate performance\n",
    "use_mps = torch.backends.mps.is_available()\n",
    "device = torch.device(\"mps\" if use_mps else \"cpu\")\n",
    "load_dtype = torch.float16 if use_mps else None\n",
    "debug_print(\"Eval device:\", device, \"| use_mps:\", use_mps, \"| load_dtype:\", load_dtype)\n",
    "\n",
    "loaded_lora_model = AutoPeftModelForSequenceClassification.from_pretrained(\n",
    "    f\"./peft/{model_name}-lora\",\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True,\n",
    "    torch_dtype=load_dtype\n",
    ")\n",
    "\n",
    "# Move model to device\n",
    "loaded_lora_model = loaded_lora_model.to(device)\n",
    "debug_print(\"PEFT model loaded and moved to device.\")\n",
    "\n",
    "# Evaluate on the test set\n",
    "lora_eval_trainer = Trainer(\n",
    "    model=loaded_lora_model,\n",
    "    eval_dataset=tokenized_test,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "lora_eval_results = lora_eval_trainer.evaluate()\n",
    "debug_print(\"PEFT eval results:\", lora_eval_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7cb9983b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-evaluating base model for comparison...\n",
      "{'peft_accuracy': 0.8175, 'base_accuracy': 0.134375}\n"
     ]
    }
   ],
   "source": [
    "# Compare PEFT vs base model accuracy\n",
    "peft_accuracy = lora_eval_results.get(\"eval_accuracy\")\n",
    "\n",
    "try:\n",
    "    debug_print(\"Re-evaluating base model for comparison...\")\n",
    "    base_results = trainer.evaluate()\n",
    "    base_accuracy = base_results.get(\"eval_accuracy\")\n",
    "except Exception as e:\n",
    "    debug_print(\"Base model eval failed:\", repr(e))\n",
    "    base_accuracy = None\n",
    "\n",
    "print({\"peft_accuracy\": peft_accuracy, \"base_accuracy\": base_accuracy})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
